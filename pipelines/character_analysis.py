"""
–ü–∞–π–ø–ª–∞–π–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –ø–æ –≤—Å–µ–º—É —Ç–µ–∫—Å—Ç—É –∫–Ω–∏–≥–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–æ–¥—Ö–æ–¥–∞ —Å –ø–∞—Ç—á–µ–º
"""
import json
from typing import List, Optional, Callable

from core.project_context import ProjectContext
from core.data_models import Character, CharacterArchive, CharacterReconResult, CharacterPatchList
from services.llm_service import LLMService
from utils import file_utils
from pipelines import prompts


class CharacterAnalysisPipeline:
    """
    –ö–ª–∞—Å—Å-–ø–∞–π–ø–ª–∞–π–Ω, –∏–Ω–∫–∞–ø—Å—É–ª–∏—Ä—É—é—â–∏–π –≤—Å—é –ª–æ–≥–∏–∫—É –∞–Ω–∞–ª–∏–∑–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ –∫–Ω–∏–≥–µ.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏:
    1. '–†–∞–∑–≤–µ–¥–∫–∞': –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ –≥–ª–∞–≤–µ.
    2. '–û–ø–µ—Ä–∞—Ü–∏—è': –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ '–ø–∞—Ç—á–∞' –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∞—Ä—Ö–∏–≤–∞.
    """

    def __init__(self, fast_llm: LLMService, powerful_llm: LLMService):
        self.fast_llm = fast_llm
        self.powerful_llm = powerful_llm
        print("‚úÖ –ü–∞–π–ø–ª–∞–π–Ω CharacterAnalysisPipeline (v3, Smart Recon) –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")

    def run(self, book_name: str, progress_callback: Optional[Callable[[float, str], None]] = None):
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –∫–Ω–∏–≥–∏, —É–∫–∞–∑–∞–Ω–Ω–æ–π –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.
        –î–û–ë–ê–í–õ–ï–ù–û: `progress_callback` –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å API.
        """
        # --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ ---
        def update_progress(progress: float, message: str):
            if progress_callback:
                progress_callback(progress, message)
            print(message)

        update_progress(0.0, "\n" + "=" * 80)
        update_progress(0.0, f"üöÄ –ó–ê–ü–£–°–ö –ü–ê–ô–ü–õ–ê–ô–ù–ê: –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ –∫–Ω–∏–≥–µ '{book_name}' üöÄ")
        update_progress(0.0, "=" * 80)

        try:
            context = ProjectContext(book_name=book_name)
            context.ensure_dirs()

            all_chapters = file_utils.get_all_chapters(context.book_dir)
            if not all_chapters:
                update_progress(1.0, f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≥–ª–∞–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤ {context.book_dir}")
                return

            master_archive = context.load_character_archive()
            update_progress(0.05, f"–ó–∞–≥—Ä—É–∂–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∞—Ä—Ö–∏–≤. –ü–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {len(master_archive.characters)}")

            total_chapters = len(all_chapters)
            update_progress(0.1, f"–ù–∞–π–¥–µ–Ω–æ {total_chapters} –≥–ª–∞–≤. –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")

            for i, (vol_path, chap_path) in enumerate(all_chapters):
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –¥–ª—è —Ç–µ–∫—É—â–µ–π –≥–ª–∞–≤—ã
                progress = 0.1 + (i / total_chapters) * 0.9

                vol_num = int(vol_path.name.split('_')[-1])
                chap_num = int(chap_path.stem.split('_')[-1])
                chapter_id = f"vol_{vol_num}_chap_{chap_num}"

                update_progress(progress, f"\n--- –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–ª–∞–≤—ã [{i+1}/{total_chapters}]: {chap_path.name} ---")

                if self._is_chapter_processed(master_archive, chapter_id):
                    update_progress(progress, f"   -> ‚úÖ –ì–ª–∞–≤–∞ {chapter_id} —É–∂–µ –±—ã–ª–∞ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Ä–∞–Ω–µ–µ. –ü—Ä–æ–ø—É—Å–∫–∞—é.")
                    continue

                chapter_text = chap_path.read_text("utf-8")
                if not chapter_text.strip():
                    update_progress(progress, "   -> ‚ö†Ô∏è –ì–ª–∞–≤–∞ –ø—É—Å—Ç–∞. –ü—Ä–æ–ø—É—Å–∫–∞—é.")
                    continue

                # --- –®–ê–ì 1: "–£–º–Ω–∞—è —Ä–∞–∑–≤–µ–¥–∫–∞" ---
                recon_result = self._perform_recon(master_archive, chapter_text)

                if not recon_result or (not recon_result.mentioned_existing_characters and not recon_result.newly_discovered_names):
                    update_progress(progress, "   -> ‚ö†Ô∏è '–†–∞–∑–≤–µ–¥–∫–∞' –Ω–µ –Ω–∞—à–ª–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ –≥–ª–∞–≤–µ. –ü—Ä–æ–ø—É—Å–∫–∞—é.")
                    continue

                all_relevant_names = recon_result.mentioned_existing_characters + recon_result.newly_discovered_names
                update_progress(progress, f"   -> –ù–∞–π–¥–µ–Ω–æ {len(all_relevant_names)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {all_relevant_names}")

                # --- –®–ê–ì 2: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤ Python ---
                relevant_chars = self._filter_archive(master_archive, recon_result.mentioned_existing_characters)
                relevant_chars_json = json.dumps([char.model_dump() for char in relevant_chars], ensure_ascii=False, indent=2)

                # --- –®–ê–ì 3: "–û–ø–µ—Ä–∞—Ü–∏—è" - –∑–∞–ø—Ä–æ—Å –ø–∞—Ç—á–∞ ---
                patch_list = self._perform_operation(relevant_chars_json, chapter_text, vol_num, chap_num)

                if not patch_list or not patch_list.patches:
                    update_progress(progress, "   -> ‚ö†Ô∏è LLM –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ –ø–∞—Ç—á–µ–π. –°—á–∏—Ç–∞–µ–º, —á—Ç–æ –≤ –≥–ª–∞–≤–µ –Ω–µ –±—ã–ª–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π.")
                    master_archive = self._add_empty_mentions(master_archive, recon_result.mentioned_existing_characters, chapter_id)
                    master_archive.save(context.get_character_archive_path())
                    update_progress(progress, "   -> –î–æ–±–∞–≤–ª–µ–Ω—ã –ø—É—Å—Ç—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π.")
                    continue

                # --- –®–ê–ì 4: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–∞—Ç—á–∞ ---
                update_progress(progress, f"   -> –®–∞–≥ 3: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ {len(patch_list.patches)} –ø–∞—Ç—á–µ–π –∫ –∞—Ä—Ö–∏–≤—É...")
                master_archive = self._apply_patch(master_archive, patch_list, vol_num, chap_num)
                update_progress(progress, f"   -> ‚úÖ –ê—Ä—Ö–∏–≤ –æ–±–Ω–æ–≤–ª–µ–Ω. –¢–µ–∫—É—â–µ–µ –∫–æ–ª-–≤–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {len(master_archive.characters)}")
                master_archive.save(context.get_character_archive_path())

            final_message_header = "\n" + "=" * 80 + "\nüéâ –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!"
            final_message_body = (
                f"   –ò—Ç–æ–≥–æ–≤—ã–π –∞—Ä—Ö–∏–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {context.get_character_archive_path()}\n"
                f"   –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {len(master_archive.characters)}\n"
                + "=" * 80
            )
            update_progress(1.0, final_message_header + "\n" + final_message_body)


        except Exception as e:
            error_message = f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ù–ï–ü–†–ï–î–í–ò–î–ï–ù–ù–ê–Ø –û–®–ò–ë–ö–ê –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ: {e}"
            update_progress(1.0, error_message)
            import traceback
            traceback.print_exc()

    def _perform_recon(self, archive: CharacterArchive, chapter_text: str) -> Optional[CharacterReconResult]:
        """–≠—Ç–∞–ø '–†–∞–∑–≤–µ–¥–∫–∏': –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π."""
        print("   -> –®–∞–≥ 1: '–£–º–Ω–∞—è —Ä–∞–∑–≤–µ–¥–∫–∞' - —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –∏ –ø–æ–∏—Å–∫ –Ω–æ–≤—ã—Ö...")
        known_chars_for_recon = [
            {"name": char.name, "aliases": char.aliases}
            for char in archive.characters
        ]
        known_chars_json = json.dumps(known_chars_for_recon, ensure_ascii=False, indent=2)
        recon_prompt = prompts.format_character_recon_prompt(chapter_text, known_chars_json)
        return self.fast_llm.call_for_pydantic(CharacterReconResult, recon_prompt)

    def _perform_operation(self, relevant_chars_json: str, chapter_text: str, vol_num: int, chap_num: int) -> Optional[CharacterPatchList]:
        """–≠—Ç–∞–ø '–û–ø–µ—Ä–∞—Ü–∏–∏': –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ç—á–∞."""
        print("   -> –®–∞–≥ 2: '–û–ø–µ—Ä–∞—Ü–∏—è' - –∑–∞–ø—Ä–æ—Å –ø–∞—Ç—á–∞ —Å –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏...")
        patch_prompt = prompts.format_character_patch_prompt(
            relevant_chars_json, chapter_text, vol_num, chap_num
        )
        return self.powerful_llm.call_for_pydantic(CharacterPatchList, patch_prompt)


    def _is_chapter_processed(self, archive: CharacterArchive, chapter_id: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –≥–ª–∞–≤—ã –≤ –∞—Ä—Ö–∏–≤–µ."""
        for char in archive.characters:
            if chapter_id in char.chapter_mentions:
                return True
        return False

    def _filter_archive(self, archive: CharacterArchive, names: List[str]) -> List[Character]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –∏–∑ –∞—Ä—Ö–∏–≤–∞ –ø–æ —Å–ø–∏—Å–∫—É –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏—Ö –∏–º–µ–Ω."""
        name_set = set(names)
        return [char for char in archive.characters if char.name in name_set]

    def _apply_patch(self, archive: CharacterArchive, patch_list: CharacterPatchList, vol: int, chap: int) -> CharacterArchive:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø–∞—Ç—á–∏ –∫ –º–∞—Å—Ç–µ—Ä-–∞—Ä—Ö–∏–≤—É."""
        char_map = {char.name: char for char in archive.characters}
        for patch in patch_list.patches:
            existing_char = char_map.get(patch.name)
            if existing_char:
                update_data = patch.model_dump(exclude_unset=True)
                if 'chapter_mentions' in update_data and update_data['chapter_mentions']:
                    existing_char.chapter_mentions.update(update_data['chapter_mentions'])
                    del update_data['chapter_mentions']
                updated_char = existing_char.model_copy(update=update_data)
                char_map[patch.name] = updated_char
            else:
                new_char_data = {
                    "name": patch.name,
                    "description": patch.description or "–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ.",
                    "spoiler_free_description": patch.spoiler_free_description or "–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ.",
                    "aliases": patch.aliases or [],
                    "chapter_mentions": patch.chapter_mentions or {},
                    "first_mention": f"–¢–æ–º {vol}, –ì–ª–∞–≤–∞ {chap}"
                }
                new_char = Character(**new_char_data)
                char_map[patch.name] = new_char
        archive.characters = list(char_map.values())
        return archive

    def _add_empty_mentions(self, archive: CharacterArchive, names_to_mention: List[str], chapter_id: str) -> CharacterArchive:
        """–î–æ–±–∞–≤–ª—è–µ—Ç '–ø—É—Å—Ç–æ–µ' —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –≤ –≥–ª–∞–≤–µ, –Ω–æ –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ –±—ã–ª–æ –ø–∞—Ç—á–∞."""
        for char in archive.characters:
            if char.name in names_to_mention:
                if chapter_id not in char.chapter_mentions:
                    char.chapter_mentions[chapter_id] = "–ü–µ—Ä—Å–æ–Ω–∞–∂ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –≤ –≥–ª–∞–≤–µ, –Ω–æ –±–µ–∑ –∑–Ω–∞—á–∏–º—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π."
        return archive

