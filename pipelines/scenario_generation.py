"""
–ü–∞–π–ø–ª–∞–π–Ω –¥–ª—è –ø–æ–ª–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–π –≥–ª–∞–≤—ã: –æ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–æ –≥–æ—Ç–æ–≤–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è.
"""
import json
from typing import List, Dict, Optional, Callable

import config
from core.project_context import ProjectContext
from core.data_models import (
    CharacterArchive,
    RawScenario,
    Scenario,
    ScenarioEntry,
    AmbientTransitionList,
    EmotionMap, ChapterSummaryArchive,
)
from services.llm_service import LLMService
from pipelines import prompts


class ScenarioGenerationPipeline:
    """
    –ö–ª–∞—Å—Å-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä, —É–ø—Ä–∞–≤–ª—è—é—â–∏–π –ø—Ä–æ—Ü–µ—Å—Å–æ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ü–µ–Ω–∞—Ä–∏—è –¥–ª—è –æ–¥–Ω–æ–π –≥–ª–∞–≤—ã.
    """

    def __init__(self, fast_llm: LLMService, powerful_llm: LLMService):
        self.fast_llm = fast_llm
        self.powerful_llm = powerful_llm
        self._load_libraries()
        print("‚úÖ –ü–∞–π–ø–ª–∞–π–Ω ScenarioGenerationPipeline –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")

    def _load_libraries(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (—ç–º–±–∏–µ–Ω—Ç, —ç–º–æ—Ü–∏–∏)."""
        print("   -> –ó–∞–≥—Ä—É–∑–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ü–µ–Ω–∞—Ä–∏—è...")
        try:
            self.ambient_library = json.loads(config.AMBIENT_LIBRARY_FILE.read_text("utf-8"))
        except (FileNotFoundError, json.JSONDecodeError) as e:
            print(f"   -> ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É —ç–º–±–∏–µ–Ω—Ç–∞: {e}")
            self.ambient_library = []

        try:
            self.emotion_library = json.loads(config.EMOTION_REFERENCE_LIBRARY_FILE.read_text("utf-8"))
            self.available_emotions = list(self.emotion_library.keys())
        except (FileNotFoundError, json.JSONDecodeError) as e:
            print(f"   -> ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É —ç–º–æ—Ü–∏–π: {e}")
            self.emotion_library = {}
            self.available_emotions = []

    def run(self, context: ProjectContext, progress_callback: Optional[Callable[[float, str], None]] = None):
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ü–µ–Ω–∞—Ä–∏—è –¥–ª—è –≥–ª–∞–≤—ã, —É–∫–∞–∑–∞–Ω–Ω–æ–π –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.
        –î–û–ë–ê–í–õ–ï–ù–û: `progress_callback` –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏–∑ API.
        """
        def update_progress(progress: float, message: str):
            if progress_callback:
                progress_callback(progress, message)
            print(message) # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤—ã–≤–æ–¥–∏—Ç—å –≤ –∫–æ–Ω—Å–æ–ª—å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏

        update_progress(0.0, "\n" + "=" * 80)
        update_progress(0.0, f"üöÄ –ó–ê–ü–£–°–ö –ü–ê–ô–ü–õ–ê–ô–ù–ê: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ü–µ–Ω–∞—Ä–∏—è –¥–ª—è –≥–ª–∞–≤—ã {context.chapter_id} üöÄ")
        update_progress(0.0, "=" * 80)

        try:
            context.ensure_dirs()
            # --- –®–∞–≥ 0: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—É—Ç–µ–π –¥–ª—è –∫—ç—à–∞ ---
            raw_scenario_path = context.chapter_output_dir / "temp_raw_scenario.json"
            ambient_enriched_path = context.chapter_output_dir / "temp_ambient_enriched.json"

            # --- –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö ---
            update_progress(0.1, "\n--- –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö ---")
            character_archive = context.load_character_archive()
            summary_archive = context.load_summary_archive()
            update_progress(0.15, f"   -> –ê—Ä—Ö–∏–≤—ã –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π ({len(character_archive.characters)} —à—Ç.) –∏ –ø–µ—Ä–µ—Å–∫–∞–∑–æ–≤ ({len(summary_archive.summaries)} —à—Ç.) —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")

            # --- –®–∞–≥ 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è "—Å—ã—Ä–æ–≥–æ" —Å—Ü–µ–Ω–∞—Ä–∏—è ---
            update_progress(0.2, "") # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Å—Ç—Ä–æ–∫–∏
            if raw_scenario_path.exists():
                update_progress(0.2, f"--- –®–∞–≥ 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è '—Å—ã—Ä–æ–≥–æ' —Å—Ü–µ–Ω–∞—Ä–∏—è (–ø—Ä–æ–ø—É—â–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫—ç—à) ---")
                raw_scenario = RawScenario.model_validate_json(raw_scenario_path.read_text("utf-8"))
            else:
                update_progress(0.2, "--- –®–∞–≥ 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è '—Å—ã—Ä–æ–≥–æ' —Å—Ü–µ–Ω–∞—Ä–∏—è ---")
                contextual_characters = self._get_contextual_characters(character_archive, context.chapter_id)
                raw_scenario = self._generate_raw_scenario(context, contextual_characters, summary_archive)
                if not raw_scenario: return
                raw_scenario_path.write_text(raw_scenario.model_dump_json(indent=2), encoding="utf-8")
                update_progress(0.5, f"   -> –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {raw_scenario_path.name}")

            scenario_as_dicts = [entry.model_dump() for entry in raw_scenario.scenario]

            # --- –®–∞–≥ 3: –û–±–æ–≥–∞—â–µ–Ω–∏–µ —ç–º–±–∏–µ–Ω—Ç–æ–º ---
            update_progress(0.55, "")
            if ambient_enriched_path.exists():
                 update_progress(0.55, f"--- –®–∞–≥ 3: –û–±–æ–≥–∞—â–µ–Ω–∏–µ —ç–º–±–∏–µ–Ω—Ç–æ–º (–ø—Ä–æ–ø—É—â–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫—ç—à) ---")
                 ambient_enriched_scenario = json.loads(ambient_enriched_path.read_text("utf-8"))
            else:
                update_progress(0.55, "--- –®–∞–≥ 3: –û–±–æ–≥–∞—â–µ–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏—è —ç–º–±–∏–µ–Ω—Ç–æ–º ---")
                ambient_enriched_scenario = self._enrich_with_ambient(context, scenario_as_dicts)
                ambient_enriched_path.write_text(json.dumps(ambient_enriched_scenario, indent=2, ensure_ascii=False), encoding="utf-8")
                update_progress(0.7, f"   -> –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {ambient_enriched_path.name}")

            # --- –®–∞–≥ 4: –û–±–æ–≥–∞—â–µ–Ω–∏–µ —ç–º–æ—Ü–∏—è–º–∏ ---
            update_progress(0.75, "\n--- –®–∞–≥ 4: –û–±–æ–≥–∞—â–µ–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏—è —ç–º–æ—Ü–∏—è–º–∏ ---")
            emotion_enriched_scenario = self._enrich_with_emotions(ambient_enriched_scenario, character_archive, context.chapter_id)

            # --- –®–∞–≥ 5: –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ---
            update_progress(0.9, "\n--- –®–∞–≥ 5: –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ---")
            final_entries = [ScenarioEntry(**entry_data) for entry_data in emotion_enriched_scenario]
            final_scenario = Scenario(entries=final_entries)
            final_scenario.save(context.scenario_file)

            # --- –®–∞–≥ 6: –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ ---
            raw_scenario_path.unlink(missing_ok=True)
            ambient_enriched_path.unlink(missing_ok=True)
            update_progress(0.95, "\n--- –®–∞–≥ 6: –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –∫—ç—à–∞ —É–¥–∞–ª–µ–Ω—ã ---")


            update_progress(1.0, "\n" + "=" * 80)
            update_progress(1.0, f"üéâ –°—Ü–µ–Ω–∞—Ä–∏–π –¥–ª—è –≥–ª–∞–≤—ã {context.chapter_id} —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω!")
            update_progress(1.0, f"   -> –§–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª: {context.scenario_file}")
            update_progress(1.0, "=" * 80)

        except FileNotFoundError as e:
            update_progress(1.0, f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
            raise e # –ü–µ—Ä–µ–¥–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –≤—ã—à–µ, —á—Ç–æ–±—ã API –º–æ–≥ –µ–≥–æ –ø–æ–π–º–∞—Ç—å
        except Exception as e:
            update_progress(1.0, f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ù–ï–ü–†–ï–î–í–ò–î–ï–ù–ù–ê–Ø –û–®–ò–ë–ö–ê –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ: {e}")
            import traceback
            traceback.print_exc()
            raise e

    def _get_contextual_characters(self, archive: CharacterArchive, chapter_id: str) -> CharacterArchive:
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –∞—Ä—Ö–∏–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ù–û–í–´–ô –û–ë–™–ï–ö–¢ CharacterArchive
        —Ç–æ–ª—å–∫–æ —Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º–∏ –¥–ª—è –≥–ª–∞–≤—ã –ø–µ—Ä—Å–æ–Ω–∞–∂–∞–º–∏.
        """
        print("   -> –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞...")
        contextual_chars = [char for char in archive.characters if chapter_id in char.chapter_mentions]
        print(f"   -> –ù–∞–π–¥–µ–Ω–æ {len(contextual_chars)} –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö –ª–∏—Ü –≤ –≥–ª–∞–≤–µ.")
        return CharacterArchive(characters=contextual_chars)

    def _generate_raw_scenario(
            self,
            context: ProjectContext,
            character_archive: CharacterArchive,
            summary_archive: ChapterSummaryArchive
    ) -> RawScenario | None:
        """
        –í—ã–∑—ã–≤–∞–µ—Ç LLM –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –≥–ª–∞–≤—ã –≤ "—Å—ã—Ä–æ–π" —Å—Ü–µ–Ω–∞—Ä–∏–π.
        """
        chapter_summary_data = summary_archive.summaries.get(context.chapter_id)
        synopsis_text = chapter_summary_data.synopsis if chapter_summary_data else None

        if synopsis_text:
            print("   -> –ù–∞–π–¥–µ–Ω –∫–æ–Ω—Å–ø–µ–∫—Ç –≥–ª–∞–≤—ã. –û–Ω –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫–∞–∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.")
        else:
            print("   -> ‚ö†Ô∏è –ö–æ–Ω—Å–ø–µ–∫—Ç –¥–ª—è –≥–ª–∞–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±—É–¥–µ—Ç –∏–¥—Ç–∏ —Ç–æ–ª—å–∫–æ –ø–æ —Ç–µ–∫—Å—Ç—É.")

        prompt = prompts.format_scenario_generation_prompt(
            context,
            character_archive,
            synopsis_text
        )
        return self.powerful_llm.call_for_pydantic(RawScenario, prompt)

    def _enrich_with_ambient(self, context: ProjectContext, entries: List[Dict]) -> List[Dict]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —ç–º–±–∏–µ–Ω—Ç –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–ø–∏—Å–∏ —Å—Ü–µ–Ω–∞—Ä–∏—è.
        """
        prompt = prompts.format_ambient_extraction_prompt(context, self.ambient_library)
        ambient_data = self.fast_llm.call_for_pydantic(AmbientTransitionList, prompt)

        if not ambient_data or not ambient_data.transitions:
            print("   -> ‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–æ—á–µ–∫ —Å–º–µ–Ω—ã —ç–º–±–∏–µ–Ω—Ç–∞. –í—Å—è –≥–ª–∞–≤–∞ –±—É–¥–µ—Ç –±–µ–∑ —Ñ–æ–Ω–æ–≤—ã—Ö –∑–≤—É–∫–æ–≤.")
            for entry in entries:
                entry['ambient'] = 'none'
            return entries

        print(f"   -> –ù–∞–π–¥–µ–Ω–æ {len(ambient_data.transitions)} —Ç–æ—á–µ–∫ —Å–º–µ–Ω—ã —ç–º–±–∏–µ–Ω—Ç–∞.")
        current_ambient = "none"
        transition_idx = 0
        for entry in entries:
            entry['ambient'] = current_ambient
            if transition_idx < len(ambient_data.transitions):
                transition = ambient_data.transitions[transition_idx]
                if entry['text'].strip().startswith(transition.triggerSentence.strip()):
                    current_ambient = transition.ambientSoundId
                    entry['ambient'] = current_ambient
                    transition_idx += 1
                    print(f"      -> –≠–º–±–∏–µ–Ω—Ç –∏–∑–º–µ–Ω–µ–Ω –Ω–∞ '{current_ambient}'")
        return entries


    def _enrich_with_emotions(self, entries: List[Dict], archive: CharacterArchive, chapter_id: str) -> List[Dict]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —ç–º–æ—Ü–∏–∏ –¥–ª—è –≤—Å–µ—Ö —Ä–µ–ø–ª–∏–∫, –≥–¥–µ —Å–ø–∏–∫–µ—Ä - –Ω–µ "–†–∞—Å—Å–∫–∞–∑—á–∏–∫".
        –≠—Ç–æ –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è –∏ –¥–∏–∞–ª–æ–≥–∏, –∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –º–æ–Ω–æ–ª–æ–≥–∏.
        """
        if not self.available_emotions:
            print("   -> ‚ö†Ô∏è –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —ç–º–æ—Ü–∏–π –ø—É—Å—Ç. –ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è.")
            for entry in entries:
                if entry.get('speaker') != "–†–∞—Å—Å–∫–∞–∑—á–∏–∫":
                    entry['emotion'] = '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ'
            return entries

        replicas_to_analyze = []
        for i, entry in enumerate(entries):
            if entry.get('speaker') and entry.get('speaker') != "–†–∞—Å—Å–∫–∞–∑—á–∏–∫":
                replicas_to_analyze.append({"id": str(i), "speaker": entry['speaker'], "text": entry['text']})

        if not replicas_to_analyze:
            print("   -> –í –≥–ª–∞–≤–µ –Ω–µ—Ç —Ä–µ–ø–ª–∏–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π.")
            return entries

        char_profiles = {
            char.name: f"–û–ë–©–ï–ï: {char.spoiler_free_description}. –í –≠–¢–û–ô –ì–õ–ê–í–ï: {char.chapter_mentions.get(chapter_id, '')}"
            for char in archive.characters if chapter_id in char.chapter_mentions
        }

        prompt = prompts.format_emotion_analysis_prompt(
            replicas_to_analyze, char_profiles, self.available_emotions
        )
        emotion_map_data = self.fast_llm.call_for_pydantic(EmotionMap, prompt)

        if not emotion_map_data:
            print("   -> ‚ùå LLM –Ω–µ —Å–º–æ–≥–ª–∞ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —ç–º–æ—Ü–∏–∏.")
            return entries

        print(f"   -> ‚úÖ LLM —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∞ {len(emotion_map_data.emotions)} —Ä–µ–ø–ª–∏–∫.")
        for entry_id_str, emotion in emotion_map_data.emotions.items():
            try:
                entry_id = int(entry_id_str)
                if entry_id < len(entries):
                    entries[entry_id]['emotion'] = emotion
            except (ValueError, IndexError):
                print(f"   -> ‚ö†Ô∏è LLM –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π ID —Ä–µ–ø–ª–∏–∫–∏: '{entry_id_str}'. –ü—Ä–æ–ø—É—Å–∫–∞—é.")
                continue
        return entries

